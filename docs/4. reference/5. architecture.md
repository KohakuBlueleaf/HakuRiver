# Architecture Overview

HakuRiver employs a simple Host-Runner architecture designed for managing command-line tasks across a small cluster of nodes, leveraging Docker for environment management.

![Architecture Diagram](../../image/HakuRiverArch.jpg)
*Diagram showing Host, Runners, Client, Shared Storage, and communication.*

## Components

1.  **Host (`hakuriver.host`)**
    *   **Role:** Central coordinator and API server.
    *   **Technology:** FastAPI (Python web framework), Peewee ORM, SQLite database.
    *   **Responsibilities:**
        *   **API Server:** Exposes HTTP endpoints for clients and runners (task submission, status checks, node registration, heartbeats, Docker management).
        *   **Node Management:** Tracks registered Runner nodes, their status (online/offline), resource capacity (cores, memory), and NUMA topology (if reported). Marks nodes as offline based on heartbeat timeouts.
        *   **Task Scheduling:** Receives task requests. Performs basic validation and assigns tasks to suitable online Runners based on target specification (hostname, optional NUMA ID) and simple availability checks (currently checks node status, basic core availability).
        *   **Task Tracking:** Stores task details (ID, command, status, assigned node, logs paths, resources, etc.) in the SQLite database. Updates status based on Runner reports.
        *   **Docker Environment Management:** Manages persistent containers on the Host itself for environment setup (via `hakuriver.docker` commands). Packages these environments into tarballs stored in shared storage using `docker commit` and `docker save`. Lists available tarballs. Provides WebSocket endpoint for interactive shells (`hakuriver.docker-shell`).
        *   **Database:** Maintains the SQLite database (`Node`, `Task` tables).
        *   **Background Tasks:** Periodically checks for dead runners.

2.  **Runner (`hakuriver.runner`)**
    *   **Role:** Agent running on each compute node, responsible for executing tasks.
    *   **Technology:** FastAPI, Docker Engine (dependency), systemd (optional fallback), `numactl` (optional dependency).
    *   **Responsibilities:**
        *   **Registration:** Registers with the Host on startup, reporting hostname, URL, core count, total memory, and NUMA topology (detected via `numactl`).
        *   **Heartbeat:** Sends periodic heartbeats to the Host, including current CPU/memory usage and lists of running/killed tasks.
        *   **Task Execution:**
            *   Receives task execution requests from the Host via its `/run` endpoint.
            *   **Docker Execution (Default):**
                *   Checks if the required Docker image (`hakuriver/<env_name>:base`) exists locally and is up-to-date compared to the latest tarball in shared storage (using timestamp comparison).
                *   If outdated or missing, loads the latest tarball from `shared_dir` using `docker load`.
                *   Executes the task command inside a *temporary* container (`docker run --rm`) using the synced image. Applies resource limits (`--cpus`, `--memory`), mounts (`shared_dir` -> `/shared`, `local_temp_dir` -> `/local_temp`, plus task-specific mounts), privileges, and network settings (currently `--network host`). Redirects stdout/stderr to files in `shared_dir`.
            *   **Systemd Execution (Fallback):**
                *   If the task requests `container_name="NULL"`, it runs the command directly on the Runner host using `sudo systemd-run --scope --collect`.
                *   Applies resource limits using systemd properties (`CPUQuota`, `MemoryMax`).
                *   If a NUMA node target (`hostname:N`) was specified, it prepends the command with `numactl --cpunodebind=N --membind=N` (requires `numactl` and appropriate permissions).
                *   Redirects stdout/stderr to files in `shared_dir`.
        *   **Status Reporting:** Sends task status updates (running, completed, failed) back to the Host's `/update` endpoint.
        *   **Task Control:** Handles requests from the Host to kill/pause/resume tasks (interacting with `docker kill`/`pause`/`unpause` or `systemctl stop`/`kill -SIGSTOP`/`kill -SIGCONT`).

3.  **Client (`hakuriver.client`, `hakuriver.docker`, `hakuriver.docker-shell`)**
    *   **Role:** Command-line tools for user interaction.
    *   **Technology:** Python scripts using `httpx` library (for HTTP/WebSocket).
    *   **Responsibilities:**
        *   `hakuriver.client`: Submits tasks (command, args, resources, target(s), container), checks task/node status, kills tasks, gets health info by calling the Host API.
        *   `hakuriver.docker`: Manages Docker environments on the Host (create/delete/start/stop containers, create/list tarballs) by calling the Host Docker API.
        *   `hakuriver.docker-shell`: Connects to the Host's WebSocket terminal endpoint for interactive shell access into Host containers.

4.  **Frontend (Optional)**
    *   **Role:** Web-based user interface.
    *   **Technology:** Vue.js, Vite, Element Plus UI library.
    *   **Responsibilities:** Provides a graphical way to monitor nodes and tasks, submit new tasks, view logs, and manage Docker environments by interacting with the Host API. Requires a separate web server (or Vite dev server) and potentially API proxy configuration.

5.  **Database (SQLite)**
    *   **Role:** Persistent storage for cluster state, managed by the Host.
    *   **Technology:** SQLite file, accessed via Peewee ORM.
    *   **Schema:**
        *   `Node` table: Stores information about each registered runner (hostname, URL, resources, status, last heartbeat, NUMA topology as JSON).
        *   `Task` table: Stores details about each submitted task (task ID, batch ID, command, args, status, assigned node, target NUMA, resource requests, log paths, timestamps, container info).

6.  **Shared Storage**
    *   **Role:** Essential filesystem accessible by the Host and all Runners.
    *   **Technology:** NFS, Samba, GlusterFS, CephFS, etc.
    *   **Responsibilities:**
        *   Stores HakuRiver container environment tarballs (created by Host, loaded by Runners).
        *   Stores stdout (`task_outputs/`) and stderr (`task_errors/`) log files for each task.
        *   Can be used for shared task input/output data (mounted as `/shared` inside containers).

## Communication Flow

![Communication Flow Diagram](images/HakuRiverFlow.jpg)
*Diagram showing interactions between Client, Host, Runner, and Shared Storage.*

1.  **Registration:** Runner starts -> Sends its info (hostname, URL, resources, NUMA) to Host `/register`. Host stores/updates info in DB.
2.  **Heartbeat:** Runner periodically -> Sends status (CPU/Mem usage, running tasks, killed tasks) to Host `/heartbeat/{hostname}`. Host updates node status and last heartbeat time in DB. Host background task checks for timed-out heartbeats.
3.  **Task Submission:** Client -> Sends task request (command, resources, targets, container) to Host `/submit`.
4.  **Task Assignment:** Host -> Validates request, finds suitable Runner(s), creates Task record(s) in DB (status 'assigning'), and asynchronously calls Runner `/run`.
5.  **Task Execution Start:** Runner -> Receives task, (syncs Docker image if needed), starts execution (via `docker run` or `systemd-run`), reports 'running' status to Host `/update`.
6.  **Task Execution End:** Runner -> Task finishes, Runner reports 'completed' or 'failed' status (with exit code) to Host `/update`.
7.  **Status Check:** Client -> Requests status for task ID from Host `/status/{task_id}`. Host retrieves from DB.
8.  **Kill Request:** Client -> Sends kill request for task ID to Host `/kill/{task_id}`. Host marks task 'killed' in DB and (if applicable) sends kill command to Runner `/kill`. Runner attempts to terminate the process/container.
9.  **Docker Management:** Client (`hakuriver.docker`) -> Sends commands (create/list/tar) to Host `/docker/*` endpoints. Host interacts with its local Docker daemon or shared storage.
10. **Docker Shell:** Client (`hakuriver.docker-shell`) -> Connects via WebSocket to Host `/docker/host/containers/.../terminal`. Host facilitates shell interaction within the container.

## Key Design Points

*   **Simplicity:** Avoids complex scheduling algorithms, focusing on direct targeting and basic availability checks.
*   **Docker as Environment:** Treats Docker images/tarballs as portable environments, synced on demand.
*   **Systemd Fallback:** Provides an option for direct execution when containerization isn't needed or possible.
*   **Centralized State:** Host maintains the primary state in its database.
*   **Shared Storage Dependency:** Relies heavily on shared storage for logs and environment distribution.
*   **Minimal Authentication:** Assumes a trusted internal network environment by default.
# Shared Storage Guide

Shared storage is a crucial component of the HakuRiver system. It enables container tarballs to be distributed to Runners and provides a common location for task logs and data. This guide explains how to set up and configure shared storage for your HakuRiver cluster.

## Key Concept: Physical vs. Logical Storage

An important concept to understand in HakuRiver's shared storage architecture:

- **Physical Storage**: The actual storage medium where data is stored (NFS server, Samba share, GlusterFS volume, etc.)
- **Logical Path**: The filesystem path where the storage is mounted on each node

**Important**: The physical storage must be the same across all nodes, but the logical mount paths can differ as long as the configuration on each node reflects its local path.

Example:
- Host: `/mnt/hakuriver-shared`
- Runner 1: `/mnt/shared`
- Runner 2: `/shared`

As long as these paths point to the same physical storage and are correctly specified in each node's config, HakuRiver will function properly.

## Shared Storage Requirements

HakuRiver needs shared storage for:

1. **Container Tarballs**: Docker images packaged for distribution to Runners
2. **Task Output Logs**: Standard output and error from tasks 
3. **Shared Data**: Input/output data for tasks

### Minimum Specifications

- **Size**: 20GB+ (dependent on image and data size)
- **Performance**: 
  - Moderate read/write speed for container distribution
  - Low latency for log file access
- **Access**: Read/write permission for all HakuRiver Host and Runner users
- **Reliability**: Sufficient for your production needs

## Storage Options

### Network File System (NFS)

NFS is a popular choice for Linux environments:

**Server Setup (Ubuntu/Debian)**:
```bash
# Install NFS server
sudo apt install nfs-kernel-server

# Create export directory
sudo mkdir -p /export/hakuriver
sudo chown nobody:nogroup /export/hakuriver
sudo chmod 777 /export/hakuriver

# Configure exports
echo '/export/hakuriver *(rw,sync,no_subtree_check,no_root_squash)' | sudo tee -a /etc/exports

# Apply exports
sudo exportfs -a
sudo systemctl restart nfs-kernel-server
```

**Client Setup (Host and Runners)**:
```bash
# Install NFS client
sudo apt install nfs-common

# Create mount point
sudo mkdir -p /mnt/hakuriver-shared

# Mount NFS share
sudo mount -t nfs nfs-server:/export/hakuriver /mnt/hakuriver-shared

# Add to /etc/fstab for persistence
echo 'nfs-server:/export/hakuriver /mnt/hakuriver-shared nfs defaults 0 0' | sudo tee -a /etc/fstab
```

### Samba/CIFS

Samba is useful for mixed environments with Windows servers:

**Server Setup (Windows or Linux)**:
On Linux:
```bash
# Install Samba
sudo apt install samba

# Configure share
sudo tee -a /etc/samba/smb.conf << EOF
[hakuriver]
   path = /export/hakuriver
   browseable = yes
   read only = no
   create mask = 0777
   directory mask = 0777
EOF

# Create directory
sudo mkdir -p /export/hakuriver
sudo chmod 777 /export/hakuriver

# Restart Samba
sudo systemctl restart smbd
```

**Client Setup (Host and Runners)**:
```bash
# Install CIFS utils
sudo apt install cifs-utils

# Create mount point
sudo mkdir -p /mnt/hakuriver-shared

# Mount CIFS share (with credentials)
sudo mount -t cifs //samba-server/hakuriver /mnt/hakuriver-shared -o username=user,password=pass

# For automated mounting, create credentials file
echo 'username=user' | sudo tee /etc/hakuriver-credentials
echo 'password=pass' | sudo tee -a /etc/hakuriver-credentials
sudo chmod 600 /etc/hakuriver-credentials

# Add to /etc/fstab with credentials
echo '//samba-server/hakuriver /mnt/hakuriver-shared cifs credentials=/etc/hakuriver-credentials,iocharset=utf8 0 0' | sudo tee -a /etc/fstab
```

### GlusterFS

GlusterFS provides a scalable distributed filesystem:

**Server Setup**:
```bash
# Install GlusterFS on all nodes in the storage cluster
sudo apt install glusterfs-server

# Start and enable service
sudo systemctl start glusterd
sudo systemctl enable glusterd

# On the first node, create a trusted storage pool
sudo gluster peer probe storage-node2
sudo gluster peer probe storage-node3

# Create a volume
sudo gluster volume create hakuriver-vol replica 3 \
  storage-node1:/gluster/brick1/hakuriver \
  storage-node2:/gluster/brick1/hakuriver \
  storage-node3:/gluster/brick1/hakuriver

# Start the volume
sudo gluster volume start hakuriver-vol
```

**Client Setup (Host and Runners)**:
```bash
# Install GlusterFS client
sudo apt install glusterfs-client

# Create mount point
sudo mkdir -p /mnt/hakuriver-shared

# Mount GlusterFS volume
sudo mount -t glusterfs storage-node1:/hakuriver-vol /mnt/hakuriver-shared

# Add to /etc/fstab for persistence
echo 'storage-node1:/hakuriver-vol /mnt/hakuriver-shared glusterfs defaults,_netdev 0 0' | sudo tee -a /etc/fstab
```

### Other Options

- **Ceph**: Highly scalable distributed storage system
- **MooseFS**: Fault-tolerant distributed file system
- **Amazon EFS/Azure Files**: Cloud-based shared storage (for cloud deployments)
- **Local shared disk**: For single-machine deployments with multiple containers

## Directory Structure

Create this directory structure in your shared storage:

```bash
# Create directory structure
mkdir -p /mnt/hakuriver-shared/hakuriver-containers
mkdir -p /mnt/hakuriver-shared/task_outputs
mkdir -p /mnt/hakuriver-shared/task_errors
mkdir -p /mnt/hakuriver-shared/shared_data

# Set permissions (adjust based on your user/group)
chmod -R 755 /mnt/hakuriver-shared
```

The structure should look like:
```
/mnt/hakuriver-shared/
├── hakuriver-containers/  # Docker image tarballs
├── task_outputs/          # stdout from tasks
├── task_errors/           # stderr from tasks
└── shared_data/           # User data shared between tasks
```

## Configuration on Different Nodes

### With Different Mount Paths

If your mount paths differ across nodes, make sure each node's configuration reflects its local path:

**Host config** (`~/.hakuriver/config.toml`):
```toml
[paths]
shared_dir = "/mnt/hakuriver-shared"
```

**Runner 1 config** (`~/.hakuriver/config.toml`):
```toml
[paths]
shared_dir = "/mnt/shared"
```

**Runner 2 config** (`~/.hakuriver/config.toml`):
```toml
[paths]
shared_dir = "/shared"
```

### Testing Configuration

Verify that shared storage is working correctly across all nodes:

1. Create a test file on the Host:
   ```bash
   echo "test file from host" > /mnt/hakuriver-shared/testfile.txt
   ```

2. Verify it's visible on Runners:
   ```bash
   # On Runner 1
   cat /mnt/shared/testfile.txt
   
   # On Runner 2
   cat /shared/testfile.txt
   ```

3. Create a test file on a Runner:
   ```bash
   # On Runner 1
   echo "test file from runner1" > /mnt/shared/runner1-test.txt
   ```

4. Verify it's visible on the Host and other Runners:
   ```bash
   # On Host
   cat /mnt/hakuriver-shared/runner1-test.txt
   
   # On Runner 2
   cat /shared/runner1-test.txt
   ```

## Performance Considerations

### Container Tarball Distribution

Container tarballs can be large (100MB-2GB). Consider these optimization strategies:

- Use a high-bandwidth network between storage and nodes
- Consider local caching if network bandwidth is limited
- Use compression-friendly base images to reduce tarball size

### Log File Access

Task logs are continuously written to shared storage:

- Ensure storage can handle concurrent writes from multiple Runners
- NFS with async option can improve performance but risks data loss on failure
- Consider log rotation for long-running clusters

### Data Access Patterns

Consider your workload's data access patterns:

- **Read-heavy**: Optimize for read performance (e.g., caching, read-ahead)
- **Write-heavy**: Ensure sufficient write bandwidth and consider write caching
- **Random access**: SSD-backed storage will perform better than HDD

## Monitoring and Maintenance

### Monitoring Shared Storage

```bash
# Check disk usage
df -h /mnt/hakuriver-shared

# Check disk IO
iostat -x 5 /dev/sdX  # Replace with actual device

# Check network throughput for NFS/Samba
iftop -i eth0
```

### Maintenance Tasks

Regular maintenance tasks for shared storage:

1. **Cleanup old tarballs**:
   HakuRiver automatically removes old container tarballs, but manual cleanup may be needed sometimes.

2. **Log rotation**:
   Set up log rotation for task output logs:

   ```bash
   # Example logrotate config
   sudo tee /etc/logrotate.d/hakuriver << EOF
   /mnt/hakuriver-shared/task_outputs/*.out {
       weekly
       rotate 4
       compress
       missingok
       notifempty
   }
   /mnt/hakuriver-shared/task_errors/*.err {
       weekly
       rotate 4
       compress
       missingok
       notifempty
   }
   EOF
   ```

3. **Check file permissions** periodically:
   ```bash
   find /mnt/hakuriver-shared -type f -not -perm -664 -ls
   find /mnt/hakuriver-shared -type d -not -perm -775 -ls
   ```

## Backup Strategies

Consider these backup options for shared storage:

1. **Snapshot-based backup**:
   - ZFS snapshots
   - LVM snapshots
   - Cloud storage snapshots (for EFS/Azure Files)

2. **File-level backup**:
   ```bash
   rsync -avz /mnt/hakuriver-shared /backup/hakuriver
   ```

3. **Container tarball backup** (most critical):
   ```bash
   rsync -avz /mnt/hakuriver-shared/hakuriver-containers /backup/containers
   ```

## Troubleshooting

### Common Issues

#### Mount Failures

```
mount.nfs: Connection timed out
```

Solution:
- Check network connectivity: `ping nfs-server`
- Verify NFS service is running: `rpcinfo -p nfs-server`
- Check firewall rules: `sudo ufw status` or `sudo firewall-cmd --list-all`

#### Permission Issues

```
Permission denied
```

Solution:
- Check file ownership: `ls -la /mnt/hakuriver-shared`
- Verify mount options (no_root_squash for NFS)
- Check user/group mappings

#### Performance Problems

```
Task output logs are delayed or slow container distribution
```

Solution:
- Check network bandwidth: `iperf -c storage-server`
- Monitor disk IO: `iostat -x 5`
- Consider network or storage upgrades if consistently slow

#### NFS Stale File Handles

```
Stale file handle
```

Solution:
- Remount the filesystem: `sudo umount /mnt/hakuriver-shared && sudo mount /mnt/hakuriver-shared`
- Check NFS server status and restart if needed

## Advanced Configuration

### High Availability Setup

For production environments, consider high-availability storage:

- **GlusterFS** with replica volumes
- **Ceph** with replicated pools
- **NFS** with failover servers (using Pacemaker/Corosync)

### Performance Tuning

#### NFS Tuning

```bash
# Mount with performance options
sudo mount -t nfs -o rw,hard,intr,rsize=32768,wsize=32768,noatime nfs-server:/export/hakuriver /mnt/hakuriver-shared
```

#### Samba/CIFS Tuning

```bash
# Mount with performance options
sudo mount -t cifs -o username=user,password=pass,rw,cache=strict,actimeo=30 //samba-server/hakuriver /mnt/hakuriver-shared
```

## Next Steps

After setting up shared storage:

1. [Configure the Host](host-setup.md) to use the shared directory
2. [Set up Runners](runner-setup.md) with proper shared storage access
3. [Review security considerations](security.md) for your storage solution
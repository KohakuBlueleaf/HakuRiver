# Host Setup Guide

This guide provides detailed instructions for setting up and configuring the HakuRiver Host server. The Host is the central component of the HakuRiver system, responsible for managing tasks, tracking nodes, handling Docker environments for preparation, and running the SSH proxy for VPS tasks.

## Hardware Requirements

For a typical small to medium cluster (3-10 nodes):

- **CPU**: 2+ cores
- **RAM**: 4GB+ (more recommended for larger clusters or high activity)
- **Disk**:
  - 40GB+ for the Host software, SQLite database, and local Docker images (used for building/committing environments).
  - Access to shared storage for container tarballs and task logs.

For larger clusters (10+ nodes):

- **CPU**: 4+ cores
- **RAM**: 8GB+
- **Disk**: 40GB+ plus shared storage.

## Operating System Requirements

HakuRiver Host has been tested on:

- Ubuntu 20.04/22.04 LTS
- Debian 10/11
- CentOS 7/8
- RHEL 7/8
- Any Linux distribution with Python 3.10+ and Docker.

## Software Prerequisites

### Python Installation

HakuRiver requires Python 3.10 or newer:

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install python3 python3-pip python3-venv

# Check version
python3 --version
```

If your distribution doesn't provide Python 3.10+, consider using pyenv or installing from source.

### Docker Installation

The Host requires Docker Engine for managing container environments (creating base containers, committing changes, saving to tarballs):

```bash
# Example for Ubuntu/Debian (adjust for your distribution)
sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io

# Add the user who will run the Host process to the docker group
sudo usermod -aG docker $USER
# You will need to log out and log back in for the group change to apply

# Check Docker installation and permissions
docker run hello-world
```

#### Docker Configuration

Considerations for `data-root`:
- Choose a location with sufficient disk space for the images you will build and commit.
- Prefer SSD for better performance.

For storage-driver:
- `overlay2` is recommended for most modern Linux distributions.
- `btrfs` can be used if your filesystem supports it.

## HakuRiver Installation

### Option 1: Install via pip

```bash
# Create a Python virtual environment (recommended)
python3 -m venv ~/.venv/hakuriver
source ~/.venv/hakuriver/bin/activate

# Install HakuRiver
pip install hakuriver
```

### Option 2: Install from Source

```bash
# Clone repository
git clone https://github.com/KohakuBlueleaf/HakuRiver.git
cd HakuRiver

# Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install
pip install -e .
```

## Host Configuration

### Create Configuration Directory and Default File

```bash
# Initialize config (creates ~/.hakuriver/config.toml if it doesn't exist)
hakuriver.init config
```

This creates a default configuration file at `~/.hakuriver/config.toml`.

### Edit Configuration

```bash
vim ~/.hakuriver/config.toml
```

#### Critical Host Configuration Settings

Ensure these settings are correctly configured:

```toml
[network]
# IP address the Host server binds to (0.0.0.0 usually fine for listening on all interfaces)
host_bind_ip = "0.0.0.0"

# Port for the Host API server. Runners and Clients connect to this port.
host_port = 8000

# Port the Host SSH proxy listens on. Clients using hakuriver.ssh connect to this port.
host_ssh_proxy_port = 8002

# The address that Runners and Clients use to reach THIS Host server.
# IMPORTANT: Must be the actual IP or hostname of this machine, accessible over the network.
host_reachable_address = "192.168.1.100" # <--- CHANGE THIS

[paths]
# Absolute path to shared storage. This must be accessible by all nodes (Host and Runners).
# The path configured here is used by the Host to find container tarballs and task logs.
# The path can be different on Runner nodes, as long as it points to the same physical storage.
shared_dir = "/mnt/hakuriver-shared" # <--- CHANGE THIS

[database]
# Path to the SQLite database file. Ensure the directory exists and is writable by the Host user.
db_file = "/opt/hakuriver/cluster_management.db" # <--- CHANGE IF NEEDED

[docker]
# The relative path within shared_dir where HakuRiver container tarballs are stored.
container_dir = "hakuriver-containers"

# The default HakuRiver environment name used if not specified in task submissions.
default_container_name = "hakuriver-base"

# The initial public Docker image used to create the default container tarball
# if no tarball exists for default_container_name when the Host starts.
initial_base_image = "python:3.12.10-alpine3.21"

# Default setting for whether tasks run privileged. Can be overridden per task.
tasks_privileged = false

# Optional list of default host-to-container directory mounts applied to ALL Docker tasks.
# Each entry should be "host_path:container_path:mode" (mode like 'ro' is optional).
# These are applied in *addition* to /shared and /local_temp mounts configured by the Runner.
additional_mounts = [] # <--- ADD CUSTOM MOUNTS HERE IF NEEDED
```

See the [Configuration Reference](../4. reference/1. configuration.md) for all available options.

### Create Directories

Ensure all necessary directories exist on the Host machine and are writable by the user running the Host process:

```bash
# Create database directory (if different from shared_dir)
sudo mkdir -p /opt/hakuriver
sudo chown $USER:$USER /opt/hakuriver # Change $USER to the user running the service

# Create shared directory mount point (if shared storage is mounted on the Host)
sudo mkdir -p /mnt/hakuriver-shared
sudo chown $USER:$USER /mnt/hakuriver-shared # Ensure Host user can write here

# Create container and log directories within the shared directory
# These are relative to shared_dir in config, but need absolute paths here
mkdir -p /mnt/hakuriver-shared/hakuriver-containers
mkdir -p /mnt/hakuriver-shared/task_outputs
mkdir -p /mnt/hakuriver-shared/task_errors
mkdir -p /mnt/hakuriver-shared/shared_data # Directory typically mounted as /shared
```

## Shared Storage Setup

The Host needs access to shared storage for:
- Storing and retrieving container tarballs.
- Accessing task output logs written by Runners.
- Accessing shared data or scripts used by tasks.

See [Shared Storage Guide](3. shared-storage.md) for detailed setup instructions. The Host's `shared_dir` configuration must match its local mount point for the shared filesystem.

### Verifying Shared Storage on the Host

Test that the shared directory is correctly configured and writable:

```bash
echo "Host test file" > /mnt/hakuriver-shared/host-test-file.txt
cat /mnt/hakuriver-shared/host-test-file.txt # Should show "Host test file"
rm /mnt/hakuriver-shared/host-test-file.txt
```

## Starting the Host Server

### Running Manually

For testing or debugging, run the Host server in the foreground:

```bash
# Activate virtual environment if used
source ~/.venv/hakuriver/bin/activate

# Start the Host
hakuriver.host

# Start with a specific config file
# hakuriver.host --config /path/to/custom-config.toml
```

### Running as Systemd Service (Recommended)

For production use, configure and run the Host as a systemd service:

```bash
# Create systemd service file (adjust --config if not using default path)
hakuriver.init service --host

# Copy the generated service file to the systemd directory
sudo cp hakuriver-host.service /etc/systemd/system/

# Reload systemd daemon to recognize the new service file
sudo systemctl daemon-reload

# Start the service
sudo systemctl start hakuriver-host.service

# Enable the service to start automatically on boot
sudo systemctl enable hakuriver-host.service

# Check the service status
sudo systemctl status hakuriver-host.service
```

See [Systemd Integration Guide](4. systemd-integration.md) for more details.

## Host Management

### Checking Host Status

- Check service status: `sudo systemctl status hakuriver-host.service`
- Check logs: `sudo journalctl -u hakuriver-host.service` (if using systemd) or check the log file specified in your config.
- Check if the API is responding: `curl http://localhost:8000/health` (replace `localhost:8000` with your configured `host_bind_ip` and `host_port`).

### Default Container Creation

On its first startup, the Host will attempt to create the default container tarball (using `initial_base_image` and `default_container_name`) in the shared directory if no tarball with that name exists. Verify its creation:

```bash
ls -la /mnt/hakuriver-shared/hakuriver-containers/ # Adjust path to your shared_dir/container_dir
```

## Web Dashboard Setup (Optional)

The web dashboard is a separate frontend application that connects to the Host API. It needs to be built and served separately.

1.  Install Node.js and npm/yarn/pnpm if not already installed.
2.  Navigate to the `frontend/` directory in the HakuRiver source code.
3.  Install dependencies: `npm install`
4.  Build for production: `npm run build`. This generates static files in `frontend/dist/`.
5.  Serve the contents of `frontend/dist/` using any static web server (e.g., Nginx, Apache, Caddy).
6.  **Important:** Configure your web server to **proxy API requests** (typically requests to `/api/`) to the running HakuRiver Host address and port (`http://<host_bind_ip>:<host_port>`). Also, configure the proxy for WebSocket connections if you want to use the terminal feature in the dashboard.

Example Nginx configuration snippet for proxying (assuming Host runs on `localhost:8000`):

```nginx
server {
    listen 80; # Or 443 for HTTPS
    server_name your_dashboard_hostname.com;

    # Serve the static files
    location / {
        root /path/to/your/hakuriver/frontend/dist;
        try_files $uri $uri/ /index.html;
    }

    # Proxy API requests to the HakuRiver Host
    location /api/ {
        proxy_pass http://localhost:8000/; # Replace with your Host's bind address and port
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade; # Required for WebSockets
        proxy_set_header Connection "upgrade";  # Required for WebSockets
        proxy_set_header Host $host;
        # Add other proxy headers as needed
    }
}
```
See the [Web Dashboard Guide](../3. user-guides/5. web-dashboard/1. overview.md) for more details.

## Advanced Host Configuration

### Firewall Configuration

Configure the host's firewall to allow incoming connections on the necessary ports:

```bash
# Ubuntu/Debian with UFW
sudo ufw allow <host_port>/tcp      # Default 8000 (Host API)
sudo ufw allow <host_ssh_proxy_port>/tcp # Default 8002 (SSH Proxy)
# If serving dashboard directly from Host:
# sudo ufw allow 80/tcp # For HTTP
# sudo ufw allow 443/tcp # For HTTPS
# Restrict access to trusted sources if possible: sudo ufw allow from <trusted_ip_range> to any port <port>
sudo ufw enable
```

### TLS/SSL Configuration

For secure connections to the Host API and Web Dashboard, set up TLS using a reverse proxy (like Nginx or Caddy) serving the dashboard and proxying to the Host, or by configuring FastAPI directly if needed (requires additional setup not covered by default HakuRiver).

### Database Backup & Recovery

Regularly back up the SQLite database file (`db_file` in config). A simple `cron` job can copy the database file to a safe location.

```bash
# Example cron job (run 'crontab -e')
0 2 * * * cp /opt/hakuriver/cluster_management.db /backup/hakuriver/db_$(date +\%Y\%m\%d_\%H\%M\%S).bak
```

### User and Permissions

It's recommended to run the Host service under a dedicated, unprivileged system user rather than `root` or your personal user, and grant it only the necessary permissions (access to the database file, shared directory, and Docker socket).

## Troubleshooting

### Common Issues

- **Cannot connect to Host:** Check firewall, `host_bind_ip`, `host_port`, and that the service is running (`sudo systemctl status hakuriver-host.service`).
- **Database access problems:** Ensure the directory for `db_file` exists and is writable by the user running the Host service. Check disk space.
- **Docker connection errors:** Ensure Docker is running (`sudo systemctl status docker`) and the user running the Host process is in the `docker` group (`groups <username>`).
- **Shared directory access problems:** Verify the directory exists, is mounted correctly, and is writable by the Host user.

For more detailed troubleshooting, see the [Troubleshooting Guide](../troubleshooting/common-issues.md).

## Next Steps

After successfully setting up the Host server:

1.  [Set up Runner nodes](2. runner-setup.md).
2.  [Configure shared storage](3. shared-storage.md) for all nodes.
3.  [Implement security measures](5. security.md) for your deployment.
4.  Test the cluster with a simple task submission from a client.
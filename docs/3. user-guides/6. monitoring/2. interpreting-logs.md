# Interpreting Logs and Debugging

Understanding how to locate and interpret logs is crucial for diagnosing issues with HakuRiver components, task execution, and overall cluster health. This guide provides an overview of where to find different types of logs and what to look for.

## Types of Logs in HakuRiver

HakuRiver generates logs from several sources:

1.  **Host Service Logs:** Messages from the central `hakuriver.host` process.
2.  **Runner Service Logs:** Messages from each `hakuriver.runner` agent process.
3.  **Command Task Logs:** Standard output (`stdout`) and standard error (`stderr`) from command tasks executed by Runners.
4.  **VPS Task (Container) Logs:** Logs generated by the process running inside the VPS container (usually `sshd`).
5.  **Docker Daemon Logs:** Logs from the Docker daemon itself on Host and Runner nodes.
6.  **Systemd Logs:** Logs related to systemd units, including the Runner service and transient scope units created for tasks.

## Locating Logs

The primary locations for logs are:

-   **Systemd Journal:** If you run Host and Runner services using `systemd`, logs are automatically captured by `journald`. This is the recommended place to check first for service-level issues.
    -   Host logs: `sudo journalctl -u hakuriver-host.service`
    -   Runner logs: `sudo journalctl -u hakuriver-runner.service`
    -   Task Systemd Scope logs (for `--container NULL` tasks): `sudo journalctl -u hakuriver-task-<task_id>.scope`
-   **Configured Log Files:** If `[paths] host_log_file` or `[paths] runner_log_file` are set in your `config.toml`, logs might also be written to these files. Check the absolute paths based on the service's `WorkingDirectory` or explicitly configured paths.
-   **Console Output:** If running Host or Runner manually in the foreground, logs are printed directly to the terminal.
-   **Shared Task Logs:** Standard output and standard error for *Command tasks* are saved to files in the shared directory:
    -   `shared_dir/task_outputs/<task_id>.out`
    -   `shared_dir/task_errors/<task_id>.err`
-   **Docker Container Logs:** For Docker tasks (both Command and VPS), Docker captures the stdout/stderr of the container's main process. For a transient Command task (`docker run --rm`), these are usually only relevant if captured elsewhere (like the shared files). For persistent VPS tasks, these are the logs from the SSH daemon or entrypoint script.
    -   Check logs for a persistent container (like a running VPS): `docker logs hakuriver-vps-<task_id>` (run on the Runner node).
-   **Docker Daemon Logs:** The Docker daemon's own logs can reveal issues with the Docker service itself. Location varies by OS (often in `journalctl -u docker.service` or `/var/log/daemon.log`, `/var/log/syslog`).

## Interpreting Logs

Look for keywords indicating problems: `ERROR`, `CRITICAL`, `WARNING`, `FATAL`, `Failed`, `Error`, `Exception`, `Timeout`, `Permission denied`, `Not found`, `No such`, `unknown`, `invalid`, `refused`, `status <non-zero>`.

### Host Service Logs (`journalctl -u hakuriver-host.service`)

-   **Startup/Shutdown Errors:** Problems initializing the database, binding to ports, or creating/checking the default container tarball.
-   **Runner Registration Issues:** "Heartbeat received from unknown hostname" (Runner not registered), "Failed to contact runner..." (Host couldn't send task/kill command to Runner).
-   **Task Submission Issues:** "Invalid target format", "Node not registered", "Insufficient cores/memory", "Failed to schedule task", database errors during task creation/update.
-   **Task Status Updates:** Confirmation messages when receiving updates from Runners.
-   **Task Dispatch Failures:** Errors logged when Host attempts to connect to Runner's `/run` endpoint.
-   **SSH Proxy Issues:** "New connection" messages, "Invalid request format", "Task ID not found", "Task is not a VPS", "Assigned node... not online", "Error connecting to Runner/VPS", "Error during data forwarding".

### Runner Service Logs (`journalctl -u hakuriver-runner.service`)

-   **Startup/Registration Errors:** "Failed to register with host" (cannot reach Host), "Docker check failed" (cannot access Docker daemon).
-   **Heartbeat Issues:** "Failed to send heartbeat" (cannot reach Host).
-   **Task Acceptance:** "Accepted task <task_id>".
-   **Docker Image Sync:** "Syncing required Docker image", "Failed to sync Docker image", "Failed to load image from tarball".
-   **Docker Command Execution:** Errors from `docker run`, `docker stop`, `docker rm`, `docker load`, `docker pause`, `docker unpause` commands run by the Runner. Look for `subprocess.CalledProcessError` or errors related to Docker daemon not running, image not found, or container issues.
-   **Systemd Command Execution (Fallback):** Errors from `sudo systemd-run`, `sudo systemctl`, `sudo numactl`. Look for `subprocess.CalledProcessError`, "Permission denied" (sudo config), "command not found".
-   **Task Process Lifecycle:** Messages indicating task process start/stop, exit codes, or signals received (e.g., kill signals).
-   **Runner-Detected Failures:** Messages like "OOM kill detected for task..." or errors specific to the Runner process managing the task.
-   **GPU Detection Errors:** If GPU info is missing, look for errors related to `pynvml` initialization or querying devices.

### Command Task Logs (`.out`, `.err` files)

-   **`stdout`:** Contains the standard output of your script or command. This is where successful processing messages, results, or progress updates should go.
-   **`stderr`:** Contains the standard error of your script or command. This is where error messages, warnings, and debugging information typically appear. Check this file first if a Command task fails with a non-zero exit code.

### VPS Task (Container) Logs (`docker logs hakuriver-vps-<task_id>`)

-   **SSH Daemon Output:** Contains logs from the `sshd` process running inside the container. Look for messages related to connection attempts, authentication failures, key issues, or SSH daemon startup problems.
-   **Entrypoint Script Output:** If your container uses a custom entrypoint or the command run by HakuRiver produces initial output, it will appear here.
-   **Application Logs:** If applications run *inside* the VPS container log to stdout/stderr, they will appear here.

### Docker Daemon Logs (`journalctl -u docker.service`)

-   **Docker Daemon Status:** Check if the daemon is running without errors.
-   **Container Start/Stop Events:** Look for messages related to containers named `hakuriver-task-<task_id>` or `hakuriver-vps-<task_id>`.
-   **Image Pull/Load Errors:** Issues pulling base images (Host) or loading tarballs (Runner) might be logged here.
-   **Runtime Errors:** Lower-level errors from the Docker runtime itself.

### Systemd Logs (`journalctl -u <service_name>`)

-   Check the status of the `hakuriver-host.service` and `hakuriver-runner.service` units. Look for logs about the service starting, stopping, or failing.
-   For Systemd fallback tasks, check the logs for the transient scope unit `hakuriver-task-<task_id>.scope`. This captures the stdout/stderr of the process launched by `systemd-run` before it's redirected to the shared files, and can sometimes show startup errors not captured elsewhere.

## Debugging Workflow

1.  **Identify the Failed Component:** Is it a task? A Runner node? The Host?
    -   Task failure: Start with task-specific logs (`.out`/`.err` for Command, `docker logs` for VPS) and `hakuriver.client status`.
    -   Runner offline: Check Runner service logs (`journalctl -u hakuriver-runner.service`) and network connectivity.
    -   Host unreachable/unresponsive: Check Host service logs (`journalctl -u hakuriver-host.service`) and network connectivity.
2.  **Check Immediate Logs:** Review the most specific logs first (task logs, Runner service logs on the assigned node).
3.  **Trace Backwards:** If the specific logs aren't clear, trace the workflow backwards using logs from other components (e.g., if Runner failed to run a task, check Host logs to see if dispatch succeeded; if Host dispatch failed, check Host config and network).
4.  **Verify Configuration and Prerequisites:** Double-check relevant parts of the `config.toml` on the involved nodes. Verify prerequisites like Docker status, shared storage mounts, and permissions.
5.  **Simplify and Reproduce:** If possible, try to reproduce the issue with a simpler task or by manually running the problematic command/Docker container/systemd-run command on the affected Runner node outside of HakuRiver.

By systematically checking the relevant logs and understanding what each source represents, you can effectively debug issues within your HakuRiver cluster.

## Next Steps

-   Review the [Troubleshooting Guide](1. common-issues.md) for specific problem-solving steps.
-   Understand [Monitoring Guide](1. overview.md) concepts for using tools to collect and view logs and metrics.
-   Consult the [API Reference](../4. reference/6. api-reference.md) for details on endpoint behavior which might help interpret Host/Runner logs.
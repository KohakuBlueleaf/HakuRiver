# Docker Container Workflow Guide

This guide explains how to create, customize, and manage Docker containers in HakuRiver to provide consistent environments for your tasks.

## Understanding the Container Workflow

HakuRiver treats Docker containers as portable, reproducible environments rather than as application deployments. The workflow follows four main steps:

1. **Create** a persistent container on the Host
2. **Customize** the container with needed software and dependencies
3. **Package** the customized container into a tarball
4. **Distribute** the tarball to Runners automatically when tasks are submitted

This approach combines interactive environment setup with automated distribution.

## Command-Line Utilities

HakuRiver provides dedicated CLI tools for container management:

- `hakuriver.docker` - Manage Docker containers and tarballs
- `hakuriver.docker-shell` - Open interactive shells into containers

## Creating a Base Container

To create a new container environment:

```bash
hakuriver.docker create-container <base-image> <container-name>
```

For example:
```bash
# Create a Python 3.11 environment
hakuriver.docker create-container python:3.11-slim my-python-env

# Create a TensorFlow environment
hakuriver.docker create-container tensorflow/tensorflow:latest-gpu my-tensorflow-env

# Create an Ubuntu environment
hakuriver.docker create-container ubuntu:22.04 my-ubuntu-env
```

This creates a persistent container on the Host that you can customize.

## Customizing Your Environment

After creating a container, you need to install software and dependencies:

```bash
# Open an interactive shell in the container
hakuriver.docker-shell <container-name>
```

For example:
```bash
hakuriver.docker-shell my-python-env
```

Once you're inside the container, you can use standard commands to install packages:

```bash
# For Python packages
pip install numpy pandas matplotlib scikit-learn torch

# For system packages in Debian/Ubuntu-based images
apt-get update
apt-get install -y gcc git curl unzip

# For system packages in Alpine-based images
apk add --no-cache gcc git curl

# Create directories, download data, or set up anything else you need
mkdir -p /app/data
```

When you're done, simply type `exit` to leave the shell.

## Package the Environment

Once your environment is set up, create a tarball to distribute to Runners:

```bash
hakuriver.docker create-tar <container-name>
```

For example:
```bash
hakuriver.docker create-tar my-python-env
```

This command:
1. Commits the container state to a new Docker image
2. Saves the image as a timestamped tarball in the shared directory
3. Older tarballs for the same environment are automatically removed

The tarball will be stored in `<shared_dir>/hakuriver-containers/` with a naming pattern of `<container-name>-<timestamp>.tar`.

## Managing Container Lifecycles

### Listing Containers

To see all containers managed by HakuRiver on the Host:

```bash
hakuriver.docker list-containers
```

### Starting and Stopping Containers

Containers can be started and stopped as needed:

```bash
# Stop a container
hakuriver.docker stop-container <container-name>

# Start a stopped container
hakuriver.docker start-container <container-name>
```

### Deleting Containers

To remove a container that's no longer needed:

```bash
hakuriver.docker delete-container <container-name>
```

This only removes the container from the Host; the tarball remains in shared storage.

## Managing Tarballs

### Listing Available Tarballs

To see all container tarballs available in shared storage:

```bash
hakuriver.docker list-tars
```

The output shows each container name, its latest timestamp, and path.

### Automatic Tarball Pruning

When you create a new tarball for a container, older tarballs for the same container are automatically removed to save space.

## Runner Synchronization

When a task is submitted using a specific container, the Runner automatically:

1. Checks if it has the latest version of the container image
2. Downloads and loads the tarball from shared storage if needed
3. Uses the container image for task execution

This process is transparent to users and ensures all tasks run in consistent environments.

## Version Management

Each tarball includes a timestamp, allowing you to track when environments were updated:

```
my-python-env-1678886400.tar
```

This is important for reproducibility, as the same environment will be used across all nodes.

## Best Practices

### Environment Naming

Use clear, descriptive names for your environments:
- `python-3.11-ml` - Python 3.11 with machine learning libraries
- `tensorflow-gpu` - TensorFlow with GPU support
- `r-4.2-stats` - R 4.2 with statistical packages

### Minimizing Image Size

Smaller images are faster to distribute. Consider:
- Using slim base images (e.g., `python:3.11-slim` instead of `python:3.11`)
- Cleaning package caches (`apt-get clean`, `rm -rf /var/lib/apt/lists/*`)
- Removing unnecessary files and build dependencies

### Updating Environments

When updating an environment:
1. Start the existing container: `hakuriver.docker start-container <name>`
2. Open a shell: `hakuriver.docker-shell <name>`
3. Make your changes (install/upgrade packages)
4. Exit and create a new tarball: `hakuriver.docker create-tar <name>`

### Testing Before Distribution

Test your environment locally before creating a tarball:
```bash
hakuriver.docker-shell <container-name>
# Run tests to verify the environment works as expected
```

## Example Workflows

### Creating a Python Data Science Environment

```bash
# Create base container
hakuriver.docker create-container python:3.9-slim python-data-science

# Open shell and install packages
hakuriver.docker-shell python-data-science

# Inside the container
pip install numpy pandas matplotlib scikit-learn seaborn jupyter
apt-get update && apt-get install -y libgomp1 # For OpenMP support
exit

# Create tarball
hakuriver.docker create-tar python-data-science

# Use in a task
hakuriver.client --target my-node --container python-data-science -- python /shared/analyze_data.py
```

### Creating a TensorFlow GPU Environment

```bash
# Create base container
hakuriver.docker create-container tensorflow/tensorflow:latest-gpu tensorflow-gpu

# Open shell and install packages
hakuriver.docker-shell tensorflow-gpu

# Inside the container
pip install pandas matplotlib sklearn keras
exit

# Create tarball
hakuriver.docker create-tar tensorflow-gpu

# Use in a task
hakuriver.client --target gpu-node --container tensorflow-gpu -- python /shared/train_model.py
```

## Next Steps

- Learn how to [submit tasks](task-submission.md) using your environments
- Explore [resource allocation](resource-allocation.md) for container-based tasks
- Set up the [web dashboard](web-dashboard.md) for visual container management
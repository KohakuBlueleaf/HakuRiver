# Docker Container Workflow Guide

This guide explains how to create, customize, and manage Docker containers in HakuRiver to provide consistent environments for your tasks, including preparing environments specifically for **VPS tasks**.

## Understanding the Container Workflow

HakuRiver treats Docker containers as portable, reproducible environments rather than as complex application deployments. The workflow follows four main steps:

1.  **Create** a persistent container on the **Host**.
2.  **Customize** the container with needed software and dependencies using an interactive shell.
3.  **Package** the customized container into a distributable tarball.
4.  **Distribute** the tarball to **Runners** automatically when tasks are submitted, where Runners load the image into their local Docker daemon.

This approach combines interactive environment setup with automated distribution and ensures reproducible task execution across nodes.

## Command-Line Utilities

HakuRiver provides dedicated CLI tools for container management, interacting with the Host server:

-   `hakuriver.docker` - Manage persistent Docker containers on the Host and tarballs in shared storage.
-   `hakuriver.docker-shell` - Open interactive WebSocket terminal shells into running containers on the Host.

## Creating a Base Container

To create a new persistent container environment on the Host:

```bash
hakuriver.docker create-container <base-image> <container-name>
```

The `<base-image>` should be a public Docker image available from a registry (like Docker Hub) that the Host can access (e.g., `ubuntu:latest`, `python:3.11-slim`, `tensorflow/tensorflow:latest-gpu`). The `<container-name>` is the logical name you assign to this environment within HakuRiver (e.g., `my-python-env`, `my-data-science`).

For example:
```bash
# Create a lightweight Python 3.11 environment base
hakuriver.docker create-container python:3.11-slim my-python-env

# Create a base for GPU tasks (requires Host to have NVIDIA Container Toolkit setup if needed by base image)
hakuriver.docker create-container nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04 my-cuda-env

# Create a general Ubuntu environment
hakuriver.docker create-container ubuntu:22.04 my-ubuntu-base
```
This command creates a container on the Host and starts it, running a command like `sleep infinity` to keep it alive. This container is where you will install software and make modifications.

## Customizing Your Environment

After creating a container, you need to install software, libraries, and dependencies specific to your tasks. This is done by getting an interactive shell into the *running* container on the Host:

```bash
hakuriver.docker-shell <container-name>
```

For example:
```bash
# Get a shell into the python environment container
hakuriver.docker-shell my-python-env
```

This command establishes a WebSocket connection to the Host, which then initiates an interactive shell (`/bin/bash` or `/bin/sh`) inside the specified container and relays input/output.

Once you're inside the container shell, you have a standard Linux environment (based on your chosen base image). You can use standard package managers (`apt-get`, `yum`, `apk`), `pip`, `conda`, etc., to install software:

```bash
# Example for a Debian/Ubuntu-based image:
# apt-get update
# apt-get install -y build-essential git htop # Install some basic tools
# pip install numpy pandas matplotlib scikit-learn torch # Install Python libraries

# Example for an Alpine-based image:
# apk update
# apk add --no-cache build-base git htop
# pip install numpy pandas matplotlib scikit-learn torch
```

You can also create directories, download datasets (though shared storage is better for large data), configure paths, or perform any other setup required for your tasks.

When you're finished customizing, simply type `exit` to leave the shell.

### Preparing Environments for VPS Tasks

If you plan to use this environment for **VPS tasks**, you **must** install and configure an SSH server inside the container:

```bash
# Example for a Debian/Ubuntu-based image:
hakuriver.docker-shell my-ubuntu-base # Get a shell

# Inside the container shell:
# apt-get update
# apt-get install -y openssh-server
# mkdir /run/sshd # Required on some Ubuntu/Debian versions
#
# Configure SSH daemon (sshd)
# By default, HakuRiver injects the public key for the 'root' user into /root/.ssh/authorized_keys.
# Ensure root login is permitted in sshd_config (PermitRootLogin yes).
# You might need to edit /etc/ssh/sshd_config:
# nano /etc/ssh/sshd_config
# Find the line 'PermitRootLogin' and ensure it is 'PermitRootLogin yes' or uncomment it.
# Save and exit nano.
#
# Start the SSH daemon (sshd). For Docker, running it in foreground is typical for entrypoint/CMD.
# HakuRiver's VPS runner will replace the container's default command with a script that
# sets up the key and starts sshd in the foreground. So you don't necessarily need to
# configure the service to start automatically within the image itself. Just ensure it's
# installed and correctly configured (especially PermitRootLogin).
#
# exit # Type exit to leave the container shell
```
Ensure the SSH server is installed and configured correctly (`PermitRootLogin yes` or for a specific user if you adapt the entrypoint) for public key authentication using the key injected by HakuRiver.

## Package the Environment

Once your environment is set up as desired in the persistent Host container, create a tarball to distribute it to Runners:

```bash
hakuriver.docker create-tar <container-name>
```

For example:
```bash
hakuriver.docker create-tar my-python-env
hakuriver.docker create-tar my-ubuntu-base
```
This command triggers a process on the Host that:
1.  Stops the specified container temporarily (for filesystem consistency).
2.  Commits the current state of the container to a new Docker image, typically tagged as `hakuriver/<container_name>:base`.
3.  Saves this image to a timestamped `.tar` file (`<container-name>-<timestamp>.tar`) within the configured `shared_dir/container_dir/`.
4.  Cleans up older tarballs for the *same* `hakuriver_container_name` in the shared directory to save space.
5.  Removes the temporary `hakuriver/<container_name>:base` image from the Host's Docker daemon (the tarball is the source for Runners).
6.  Restarts the original persistent container on the Host.

The timestamp ensures versioning of your environments.

## Managing Container Lifecycles (on Host)

You can manage the persistent containers on the Host using `hakuriver.docker`:

### Listing Containers

To see all persistent containers managed by HakuRiver on the Host:

```bash
hakuriver.docker list-containers
```

This shows their Docker ID, Name, Image, and current Status (Running, Stopped, etc.).

### Starting and Stopping Containers

Containers can be started and stopped as needed (e.g., before committing changes, or if you stopped one manually):

```bash
# Stop a running container
hakuriver.docker stop-container <container-name>

# Start a stopped container
hakuriver.docker start-container <container-name>
```

### Deleting Containers

To remove a persistent container from the Host that's no longer needed:

```bash
hakuriver.docker delete-container <container-name>
```
**Note:** This only removes the container instance from the Host. The tarballs previously created from it in shared storage remain available for Runners until manually deleted (a feature not yet fully exposed via API/CLI).

## Managing Tarballs (in Shared Storage)

You can see the packaged environments available for Runners:

### Listing Available Tarballs

To see all container tarballs available in the configured `shared_dir/container_dir/`:

```bash
hakuriver.docker list-tars
```

The output lists each unique HakuRiver container name found, along with the timestamp and filename of the latest version and potentially a list of older versions.

### Automatic Tarball Pruning

When you create a new tarball for a specific `hakuriver_container_name` using `hakuriver.docker create-tar`, older tarballs with the *same name prefix* are automatically removed from the shared directory to save disk space.

## Runner Synchronization (Automatic)

When a Command task or VPS task is submitted with `--container <env_name>` targeting a Runner:
1.  The Runner checks if it has a local Docker image tagged `hakuriver/<env_name>:base`.
2.  It compares the creation timestamp of its local image with the timestamp embedded in the filename of the *latest* tarball (`<env_name>-<timestamp>.tar`) found in the shared directory.
3.  If the local image is missing or older than the latest tarball, the Runner automatically downloads and loads the latest tarball into its local Docker daemon using `docker load`.
4.  The task is then executed using this guaranteed-latest version of the image.

This synchronization process is automatic and ensures consistency across Runners using the same environment name.

## Version Management

Each tarball includes a Unix timestamp in its filename (`<container-name>-<timestamp>.tar`), indicating when that specific version of the environment was created. While HakuRiver's standard task submission uses the *latest* tarball available for a given container name, this timestamping allows you to track changes and potentially revert to older versions manually if needed (though submitting older versions is not a standard HakuRiver feature today).

## Best Practices

-   **Environment Naming**: Use clear, descriptive names for your HakuRiver environments (e.g., `python-3.9-ml`, `ubuntu-dev`, `cuda-11.8-tf`).
-   **Minimizing Image Size**: Smaller images transfer faster to Runners. Use minimal base images (e.g., `-slim`, `-alpine` variants) and clean up package manager caches (`apt-get clean`, `rm -rf /var/lib/apt/lists/*`) after installing software inside the container shell.
-   **Updating Environments**: To update an environment, get a shell into its persistent container on the Host (`hakuriver.docker-shell`), make changes, exit, and run `hakuriver.docker create-tar` again. This creates a new, updated tarball.
-   **Testing Before Packaging**: Before running `hakuriver.docker create-tar`, ensure your environment works correctly by running test commands or scripts within the `hakuriver.docker-shell` session.
-   **Containerizing Dependencies**: Install all task-specific dependencies (libraries, tools, etc.) *inside* the container environment. This is the core purpose of this workflow.

## Example Workflow: Creating a Data Science Environment

```bash
# On Client machine (connected to Host)

# 1. Create a base container from a Python image
hakuriver.docker create-container python:3.9-slim python-data-science

# 2. Get interactive shell and install libraries
hakuriver.docker-shell python-data-science
# Inside container:
# apt-get update && apt-get install -y build-essential
# pip install numpy pandas matplotlib seaborn scikit-learn jupyterlab
# exit

# 3. Package the customized environment into a tarball
hakuriver.docker create-tar python-data-science

# 4. Use this environment for a task (e.g., on Runner 'nodeA')
# hakuriver.task submit --target nodeA --container python-data-science -- python /shared/analyze_data.py
```

By following this workflow, you can ensure that all tasks specifying ` --container python-data-science` will run in a consistent environment with the necessary data science libraries installed, regardless of which Runner node they are assigned to.
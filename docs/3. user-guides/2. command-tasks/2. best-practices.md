# Command Task Best Practices

This guide provides tips for designing reliable and efficient tasks in KohakuRiver.

---

## Script Design

### Keep Tasks Focused

Design tasks to perform a single, well-defined job:

| Good | Bad |
|------|-----|
| Process one file | Process all files in a directory |
| Train one model | Train multiple models sequentially |
| Run one test suite | Run tests, then deploy, then notify |

### Use Command-Line Arguments

Pass parameters via arguments, not hardcoded values:

```python
# Good
import argparse
parser = argparse.ArgumentParser()
parser.add_argument('--input', required=True)
parser.add_argument('--output', required=True)
args = parser.parse_args()

# Bad
input_file = "/shared/data/hardcoded_input.csv"
```

### Use Meaningful Exit Codes

| Exit Code | Meaning |
|-----------|---------|
| `0` | Success |
| `1` | General error |
| `2` | Invalid arguments |
| Other non-zero | Specific errors |

```bash
#!/bin/bash
set -e  # Exit on error

if [ -z "$1" ]; then
    echo "Error: Input file required" >&2
    exit 2
fi

# Process...
exit 0
```

---

## Output and Logging

### Write to stdout/stderr

KohakuRiver captures both streams:

```python
import sys

print("Processing started...")           # stdout
print(f"Error: {e}", file=sys.stderr)   # stderr
```

### Use Logging Frameworks

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

logger.info("Starting task")
logger.error("Failed to process file")
```

### Include Progress Updates

```python
for i, item in enumerate(items):
    process(item)
    if i % 100 == 0:
        print(f"Processed {i}/{len(items)} items")
```

---

## Leveraging Shared Storage

### Directory Layout

```
/shared/                      # Mounted from shared_data/
├── scripts/                  # Your scripts
├── data/                     # Input data
│   └── input.csv
└── results/                  # Output data
    └── output.json
```

### Path Usage

| Path | Use For |
|------|---------|
| `/shared/` | Input data, scripts, persistent output |
| `/local_temp/` | Temporary files, scratch space |

### Example

```bash
#!/bin/bash
INPUT="/shared/data/input.csv"
OUTPUT="/shared/results/output_$(date +%s).json"
TEMP="/local_temp/working"

mkdir -p "$TEMP"
process "$INPUT" --temp-dir "$TEMP" --output "$OUTPUT"
rm -rf "$TEMP"
```

---

## Resource Requests

### CPU Cores

| Workload Type | Recommended |
|---------------|-------------|
| Single-threaded | `--cores 1` |
| Multi-threaded | Match thread count |
| IO-bound | `--cores 1-2` |

```bash
# Match cores to actual parallelism
kohakuriver task submit "python parallel.py --workers 4" -t node1 --cores 4
```

### Memory Limits

| Workload | Guideline |
|----------|-----------|
| Light scripts | `--memory 512M` to `1G` |
| Data processing | `--memory 4G` to `8G` |
| ML training | `--memory 16G+` |

```bash
# Set based on peak usage
kohakuriver task submit "python memory_heavy.py" -t node1 --memory 8G
```

### GPUs

Request only what you need:

```bash
# Single GPU
kohakuriver task submit "python train.py" -t node1::0 --container cuda-env

# Multiple GPUs
kohakuriver task submit "python train.py" -t node1::0,1 --container cuda-env
```

---

## Error Handling

### Bash Scripts

```bash
#!/bin/bash
set -e          # Exit on error
set -u          # Exit on undefined variable
set -o pipefail # Catch pipe failures

trap 'echo "Error on line $LINENO" >&2' ERR

# Your code...
```

### Python Scripts

```python
import sys
import traceback

def main():
    try:
        # Your code...
        pass
    except FileNotFoundError as e:
        print(f"Input file not found: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"Unexpected error: {e}", file=sys.stderr)
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## Idempotency

Design tasks to be safely re-runnable:

### Good Pattern

```python
output_path = "/shared/results/output.json"

# Check if already done
if os.path.exists(output_path):
    print("Output already exists, skipping")
    sys.exit(0)

# Process and save atomically
temp_path = "/local_temp/output_temp.json"
with open(temp_path, 'w') as f:
    json.dump(result, f)
shutil.move(temp_path, output_path)
```

### Bad Pattern

```python
# Appends on each run - not idempotent!
with open(output_path, 'a') as f:
    f.write(result)
```

---

## Example: Complete Script

```bash
#!/bin/bash
# process_data.sh - Example KohakuRiver task script

set -euo pipefail

# Parse arguments
INPUT_FILE="${1:-}"
OUTPUT_DIR="${2:-/shared/results}"
THREADS="${3:-1}"

# Validate
if [ -z "$INPUT_FILE" ]; then
    echo "Usage: $0 <input_file> [output_dir] [threads]" >&2
    exit 2
fi

if [ ! -f "/shared/$INPUT_FILE" ]; then
    echo "Error: Input file not found: /shared/$INPUT_FILE" >&2
    exit 1
fi

# Setup
mkdir -p "$OUTPUT_DIR"
TEMP_DIR="/local_temp/processing_$$"
mkdir -p "$TEMP_DIR"

cleanup() {
    rm -rf "$TEMP_DIR"
}
trap cleanup EXIT

# Process
echo "Processing $INPUT_FILE with $THREADS threads..."
echo "Running on node: $(hostname)"

# Your processing command here
cp "/shared/$INPUT_FILE" "$OUTPUT_DIR/processed_$(basename $INPUT_FILE)"

echo "Done. Output in $OUTPUT_DIR"
exit 0
```

Submit:

```bash
kohakuriver task submit "/shared/scripts/process_data.sh data.csv results 4" \
  -t node1 --cores 4 --memory 4G --container my-env
```

---

## Checklist

Before submitting a task, verify:

- [ ] Script handles arguments correctly
- [ ] Exit codes indicate success/failure
- [ ] Errors go to stderr
- [ ] Resource requirements are realistic
- [ ] Input/output paths use `/shared/`
- [ ] Temporary files use `/local_temp/`
- [ ] Task is idempotent (if re-running is expected)

---

## Next Steps

1. [VPS task management](../3.%20vps-tasks/1.%20management.md)
2. [GPU allocation](../4.%20gpu-allocation/1.%20allocation.md)
3. [Monitoring](../6.%20monitoring/1.%20monitoring.md)

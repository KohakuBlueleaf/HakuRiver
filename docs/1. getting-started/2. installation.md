# Installation Guide

This guide walks you through the process of installing HakuRiver on your host machine, runner nodes, and client machines.

## Prerequisites

Before installing HakuRiver, ensure your infrastructure meets these requirements:

### Hardware Requirements
- **Host Node**: Any machine capable of running Python and Docker. Needs sufficient disk space for the software, database, Host-side Docker containers, and access to shared storage.
- **Runner Nodes**: Compute machines with sufficient CPU, RAM, and potentially GPU resources for your tasks. Needs disk space for the Runner software, Docker images, and access to shared storage.
- **Shared Storage**: A filesystem accessible from all nodes (Host and Runners) at a consistent logical path.
- **Network**: All nodes must be able to communicate with each other. Clients must be able to reach the Host API port (`host_port`) and the Host SSH proxy port (`host_ssh_proxy_port`). Host must be able to reach Runner API ports (`runner_port`). Runners must be able to reach the Host API port.

### Software Requirements
- **Python**: Version 3.10 or newer on all machines.
- **Docker Engine**: Installed and running on both the Host and all Runner nodes. Ensure the user running HakuRiver components has permission to interact with the Docker daemon (usually via the `docker` group or passwordless `sudo`).
- **Shared Filesystem**: NFS, Samba, GlusterFS, or any other shared filesystem solution mounted on all nodes.
- **Systemd & `numactl`**: Optional on Runner nodes. Required for the systemd fallback execution method (`systemd-run`, `systemctl`) and NUMA targeting (`numactl`). Passwordless `sudo` for these commands may be required depending on the runner user.
- **NVIDIA Drivers & `pynvml`**: Optional on Runner nodes. Required for GPU reporting and allocation features. Ensure compatible NVIDIA drivers are installed and `pynvml` can be installed (often via `pip install hakuriver[gpu]`).
- **SSH Client**: Required on client machines for accessing VPS tasks using `hakuriver.ssh`.

### Docker Configuration
HakuRiver typically uses Docker's default configuration (storage driver, data-root), but you should verify:
1. Docker daemon is running on Host and Runners.
2. The user running HakuRiver can use Docker commands (e.g., `docker ps`, `docker run`, `docker load`). Test with `docker run hello-world`.
3. Ensure Docker's data-root (`/var/lib/docker` by default) has sufficient space for image storage on both Host (for base images) and Runners (for loaded task images).

## Installation Methods

Install HakuRiver on the **Host, all Runner nodes, and Client machines**.

### Option 1: Install via pip (Recommended)

```bash
# Using pip (recommended)
python -m pip install hakuriver

# To include GPU monitoring support on Runners (requires pynvml & nvidia drivers)
# python -m pip install "hakuriver[gpu]"
```

This will install the latest stable version from PyPI.

### Option 2: Install from GitHub

To install the latest development version directly from GitHub:

```bash
python -m pip install git+https://github.com/KohakuBlueleaf/HakuRiver.git

# For GPU support from source
# python -m pip install "git+https://github.com/KohakuBlueleaf/HakuRiver.git#egg=hakuriver[gpu]"
```

### Option 3: Manual Installation from Source

You can also clone the repository and install locally:

```bash
git clone https://github.com/KohakuBlueleaf/HakuRiver.git
cd HakuRiver
pip install -e .

# For GPU support locally
# pip install ".[gpu]"
```

## Post-Installation Configuration

After installing HakuRiver, you need to create the default configuration file on **each machine (Host, Runners, Clients)**:

```bash
hakuriver.init config
```

This creates a configuration file at `~/.hakuriver/config.toml` which you'll need to customize:

```bash
vim ~/.hakuriver/config.toml
```

### Critical Configuration Settings

Review and adjust these settings on **all machines**:

1.  `[network] host_reachable_address`: **Must** be the IP/hostname of the Host reachable by Runners and Clients.
2.  `[network] runner_address`: **Must** be the IP/hostname of *this specific Runner* accessible by the Host. (Needs to be unique per Runner). Only set on Runner nodes.
3.  `[network] host_port` and `[network] runner_port`: Default is 8000 and 8001, change if needed. Ensure firewalls allow traffic on these ports.
4.  `[network] host_ssh_proxy_port`: The port the Host listens on for SSH proxy connections (default 8002). Clients need to reach this port. Only set on Host and Client machines (client needs to know the port).
5.  `[paths] shared_dir`: Absolute path to your shared storage. **Must be the same physical filesystem** but the logical path can differ on each node (configure accordingly on each node). Ensure this directory exists and is writable by the user running HakuRiver components.
6.  `[paths] local_temp_dir`: Absolute path to local temp storage on Runner nodes (must exist and be writable).
7.  `[paths] numactl_path`: Path to `numactl` binary on Runner nodes (only needed if using systemd fallback with NUMA targeting).
8.  `[database] db_file`: Path for the Host's SQLite database. Only set on the Host node.
9.  `[docker] container_dir`: Subdirectory within `shared_dir` for container tarballs. Set on Host and Runners.

See the [Configuration Reference](../4. reference/1. configuration.md) for detailed explanations of all settings.

## Installation Testing

After installation, verify that HakuRiver CLI tools are accessible on each machine:

```bash
hakuriver.client --help
hakuriver.task --help
hakuriver.vps --help
hakuriver.docker --help
hakurun --help # For local utility
```

You should see the help messages for each command.

## Setting Up Systemd Services (Optional)

For production use, it's highly recommended to run HakuRiver components as systemd services to ensure they start automatically on boot and are managed properly.

On the **Host machine**:
```bash
# Create service file in the current directory
hakuriver.init service --host [--config /path/to/host.toml]

# Move the service file to systemd directory and reload
sudo cp hakuriver-host.service /etc/systemd/system/
sudo systemctl daemon-reload

# Start and enable the service
sudo systemctl start hakuriver-host.service
sudo systemctl enable hakuriver-host.service

# Check status
sudo systemctl status hakuriver-host.service
```

On **each Runner node**:
```bash
# Create service file in the current directory
hakuriver.init service --runner [--config /path/to/runner.toml]

# Move the service file to systemd directory and reload
sudo cp hakuriver-runner.service /etc/systemd/system/
sudo systemctl daemon-reload

# Start and enable the service
sudo systemctl start hakuriver-runner.service
sudo systemctl enable hakuriver-runner.service

# Check status
sudo systemctl status hakuriver-runner.service
```

See the [Systemd Integration Guide](../2. admin-guides/4. systemd-integration.md) for more details, including potential `sudo` requirements for the runner user.

## Next Steps

Now that you have installed HakuRiver and performed initial configuration, proceed to the [Quick Start Guide](3. quick-start.md) to learn how to get your cluster running and execute your first tasks.

## Troubleshooting

If you encounter issues during installation:

1.  Verify Python version: `python --version` (should be 3.10+).
2.  Verify Docker installation and access: `docker info`, `docker run hello-world`.
3.  Check shared directory is accessible and writable on all nodes using the user running HakuRiver: `ls -la /mnt/shared/hakuriver`, `touch /mnt/shared/hakuriver/testfile`.
4.  Ensure network connectivity between Host and Runners on the configured API ports (`host_port`, `runner_port`). Use `ping` or `telnet <ip> <port>`.
5.  Ensure network connectivity between Clients and Host on the API port and SSH proxy port (`host_port`, `host_ssh_proxy_port`).
6.  Check logs for detailed error messages. If running manually, errors go to the console. If using systemd, use `sudo journalctl -u hakuriver-host.service` and `sudo journalctl -u hakuriver-runner.service`.

For more help, refer to the [Troubleshooting Guide](../troubleshooting/common-issues.md).